{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset_builder, load_dataset, get_dataset_infos, get_dataset_config_names, list_datasets\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from operator import itemgetter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List, Dict, Any, Optional, Union, Tuple, Callable\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_by_name(name):\n",
    "    df = pd.read_csv(f\"data/{name}_data.csv\")\n",
    "    df.columns.values[0] = 'text'\n",
    "    df.columns.values[1] = 'class'      \n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(df_dict, test_size=0.2):\n",
    "    df_dict_train = {}\n",
    "    df_dict_test = {}\n",
    "\n",
    "    for dataset, df in df_dict.items():\n",
    "        df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "        df_dict_train[dataset] = df_train\n",
    "        df_dict_test[dataset] = df_test\n",
    "    return df_dict_train, df_dict_test\n",
    "\n",
    "def construct_example_strings(df, str_fn=None):\n",
    "    df_dict_examples = {}\n",
    "    for dataset_name, dataset_df in df.items():\n",
    "        if str_fn:\n",
    "            df_dict_examples[dataset_name] = dataset_df.apply(str_fn, axis=1).tolist()\n",
    "        else:\n",
    "            df_dict_examples[dataset_name] = dataset_df.apply(lambda x: f\"{x['text']}[{x['class']}]\", axis=1).tolist()\n",
    "    return df_dict_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_datasets = [\"lowercase\", \n",
    "               \"imdb_numbers\", \n",
    "               \"imdb_digits\", \n",
    "               \"backpack\", \n",
    "               \"sd_addition\",\n",
    "               \"gpt_digits\"]\n",
    "df_dict = {name: load_dataset_by_name(name) for name in my_datasets}\n",
    "\n",
    "dict_train, dict_test = split_datasets(df_dict)\n",
    "\n",
    "str_fn = lambda x: f\"sentence: {x['text']}\\nclassification: {x['class']}\"\n",
    "dict_examples = construct_example_strings(dict_train, str_fn=str_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a few examples from dict_examples\n",
    "for dataset, examples in dict_examples.items():\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    print(\"Examples:\")\n",
    "    for example in examples[:3]:\n",
    "        print(example)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_types = {\"gpt-4\": \"gpt-4-1106-preview\", \"gpt-3\":\"gpt-3.5-turbo-1106\"}\n",
    "\n",
    "@dataclass\n",
    "class RunArgs():\n",
    "    n_test = 15\n",
    "    n_examples = 15\n",
    "    test_dataset_name = \"gpt_digits\"\n",
    "    model = \"gpt-3.5-turbo-1106\"\n",
    "    template = \"templates/classification_4.yaml\"\n",
    "    randomize_examples = True\n",
    "    label_rename_map = {\"True\":\"Type A\", \"False\":\"Type B\"}\n",
    "\n",
    "args = RunArgs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_examples(x):\n",
    "#     dataset = x['dataset']\n",
    "#     examples = dict_examples[dataset]\n",
    "\n",
    "#     if 'n_examples' in x:\n",
    "#         n_examples = x['n_examples']\n",
    "#         examples = examples[:n_examples]\n",
    "\n",
    "#     \"\\n\".join(examples)\n",
    "#     return examples\n",
    "\n",
    "def get_output_parser():\n",
    "    response_schemas = [\n",
    "        ResponseSchema(name=\"sentence\", description=\"the sentence to classify\"),\n",
    "        ResponseSchema(name=\"classification\", description=\"the classification of the sentence, Type A or Type B\")\n",
    "    ]\n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "    return output_parser\n",
    "\n",
    "# def classify_multiple(test_df: pd.DataFrame,) -> str:\n",
    "#     sentences = '\\n'.join(['sentence: ' + s for s in test_data['text'].tolist()])\n",
    "#     inputs = {\"input\": sentences, \"dataset\": args.test_dataset_name}\n",
    "#     pred = chain.invoke(inputs)\n",
    "#     return pred\n",
    "\n",
    "def classify_individually(test_df, chain):\n",
    "    results = []\n",
    "    for index, row in tqdm(test_df.iterrows()):\n",
    "        sentence = row['text']\n",
    "        ground_truth = row['class']\n",
    "        \n",
    "        inputs = {\"input\": sentence, \"dataset\": args.test_dataset_name}\n",
    "        out = chain.invoke(inputs)\n",
    "\n",
    "        # parsed = output_parser.parse(out.content)\n",
    "        # assert sentence == parsed['sentence']\n",
    "        # pred = parsed['classification']\n",
    "\n",
    "        results.append(out.content)\n",
    "        # results.append((sentence, ground_truth, pred))\n",
    "    \n",
    "    return results\n",
    "    # return pd.DataFrame(results, columns=[\"text\", \"ground_truth\", \"prediction\"])\n",
    "\n",
    "def get_examples(dataset_name: str, n_examples: int, randomize_examples: bool = False, label_rename_map: Dict = None) -> List[str]:\n",
    "    df_examples = dict_train[dataset_name]\n",
    "\n",
    "    if randomize_examples:\n",
    "        df_examples = df_examples.sample(n_examples)\n",
    "    else:\n",
    "        df_examples = df_examples[:n_examples]\n",
    "    \n",
    "    df_examples.columns = ['sentence', 'classification']\n",
    "    df_examples['classification'].astype(bool)\n",
    "    if label_rename_map:\n",
    "        df_examples['classification'] = df_examples['classification'].apply(lambda x: label_rename_map[str(x)])\n",
    "\n",
    "    return df_examples\n",
    "\n",
    "def json_formatted_examples(examples = pd.DataFrame) -> List[str]:\n",
    "    json_examples = examples.to_json(orient=\"records\")\n",
    "    return json_examples\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = ChatOpenAI(model=args.model)\n",
    "\n",
    "# prompt\n",
    "classification_template = load_prompt(args.template)\n",
    "\n",
    "# output parser\n",
    "output_parser = get_output_parser()\n",
    "classification_template = classification_template.partial(output_format=output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        examples=RunnableLambda(get_examples)\n",
    "    )\n",
    "    | classification_template\n",
    "    | model\n",
    ")\n",
    "\n",
    "# chain = (\n",
    "#     RunnablePassthrough.assign(\n",
    "#         examples=RunnableLambda(get_examples)\n",
    "#     )\n",
    "#     | {\"out\": classification_template | model | RunnableLambda(lambda x: x.content)}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = get_examples(\n",
    "    args.test_dataset_name, \n",
    "    args.n_examples, \n",
    "    randomize_examples=args.randomize_examples,\n",
    "    label_rename_map=args.label_rename_map\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"sentence\":\"The human brain weighs about 3 pounds.\",\"classification\":\"Type A\"},{\"sentence\":\"India became independent in 1947.\",\"classification\":\"Type A\"},{\"sentence\":\"Shakespeare wrote \\'Hamlet\\'.\",\"classification\":\"Type B\"},{\"sentence\":\"The heart circulates blood throughout the body.\",\"classification\":\"Type B\"},{\"sentence\":\"The Titanic sank in 1912.\",\"classification\":\"Type A\"},{\"sentence\":\"Mona Lisa has no eyebrows.\",\"classification\":\"Type B\"},{\"sentence\":\"A group of crows is called a murder.\",\"classification\":\"Type B\"},{\"sentence\":\"Venus is the hottest planet in our solar system.\",\"classification\":\"Type B\"},{\"sentence\":\"The human liver has over 500 functions.\",\"classification\":\"Type B\"},{\"sentence\":\"The human body has 206 bones.\",\"classification\":\"Type A\"},{\"sentence\":\"2 apples are on the table.\",\"classification\":\"Type A\"},{\"sentence\":\"Neon lights were first demonstrated in 1910.\",\"classification\":\"Type A\"},{\"sentence\":\"The Dead Sea is one of the saltiest bodies of water in the world.\",\"classification\":\"Type B\"},{\"sentence\":\"An elephant\\'s pregnancy lasts about 22 months.\",\"classification\":\"Type A\"},{\"sentence\":\"Water covers about 71% of the Earth\\'s surface.\",\"classification\":\"Type A\"}]'"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_formatted_examples(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = dict_test[args.test_dataset_name][:args.n_test]\n",
    "sentences = '\\n'.join(['sentence: ' + s for s in test_data['text'].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sente\n"
     ]
    }
   ],
   "source": [
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # results_df = classify_individually(test_data)\n",
    "# preds = classify_multiple(sentences)\n",
    "# preds\n",
    "# out = preds.content[8:-5]\n",
    "# out = json.loads(out)\n",
    "\n",
    "# results_df = pd.DataFrame(preds).rename(columns={\"sentence\": \"text\", \"classification\": \"prediction\"})\n",
    "# results_df['ground_truth'] = test_data['class'].tolist()\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent correct: 0.95\n"
     ]
    }
   ],
   "source": [
    "# calculate percent correct in results_df\n",
    "correct = results_df['ground_truth'] == results_df['prediction']\n",
    "print(f\"percent correct: {correct.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "# for index, row in test.iterrows():\n",
    "#     text = row['text']\n",
    "#     ground_truth = row['class']\n",
    "    \n",
    "#     inputs = {\"input\": text, \"dataset\": test_dataset_name}\n",
    "#     pred = chain.invoke(inputs)\n",
    "#     results.append((text, ground_truth, pred))\n",
    "\n",
    "#     print(text)\n",
    "#     print(f\"predicted: {pred}\")\n",
    "#     print(f\"actual: {ground_truth}\")\n",
    "#     print()\n",
    "\n",
    "# results_df = pd.DataFrame(results, columns=[\"text\", \"ground_truth\", \"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = \"\\n\".join([f\"{i+1}. {sentence}\" for i, sentence in enumerate(test['text'].tolist())])\n",
    "# def classify_many():\n",
    "#     # input = \"\\n\".join([f\"{i+1}. {sentence}\" for i, sentence in enumerate(test['text'].tolist())])\n",
    "#     inputs = {\"input\": input, \"dataset\": test_dataset_name, \"n_examples\": 100}\n",
    "#     pred = chain.invoke(inputs)\n",
    "#     return pred\n",
    "\n",
    "# pred = classify_many()\n",
    "\n",
    "# def classify_one(sentence):\n",
    "#     inputs = {\"input\": sentence, \"dataset\": test_dataset_name, \"n_examples\": 100}\n",
    "#     pred = chain.invoke(inputs)\n",
    "#     return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prediction</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3 + 3 = 6</td>\n",
       "      <td>Type A</td>\n",
       "      <td>Type A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8 + 8 = 16</td>\n",
       "      <td>Type A</td>\n",
       "      <td>Type A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6 + 0 = 4</td>\n",
       "      <td>Type B</td>\n",
       "      <td>Type B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 + 1 = 5</td>\n",
       "      <td>Type A</td>\n",
       "      <td>Type A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 + 3 = 18</td>\n",
       "      <td>Type B</td>\n",
       "      <td>Type B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text prediction ground_truth\n",
       "0   3 + 3 = 6     Type A       Type A\n",
       "1  8 + 8 = 16     Type A       Type A\n",
       "2   6 + 0 = 4     Type B       Type B\n",
       "3   4 + 1 = 5     Type A       Type A\n",
       "4  4 + 3 = 18     Type B       Type B"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adschat-jmOWAmzn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
